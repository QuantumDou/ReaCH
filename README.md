# TriCL

Code for paper "Diagnostic Reasoning Enhanced Radiology Report Generation via Hierarchical Contrastive Learning"

## ğŸ› ï¸ Pre-trained Weights Setup
**BiomedCLIP** 
- Purpose: Offline retrieval
- Source: [Hugging Face](<https://huggingface.co/microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224>)

**CheXbert**
- Purpose: Validation
- Source:[GitHub](<https://github.com/stanfordmlgroup/CheXbert>)


**Directory Structure Example:**
```
checkpoint/
â”œâ”€â”€ Biomedclip/      
â””â”€â”€ chexbert/        
```

---

## ğŸ“šDataset Download

### MIMIC-CXR Dataset:
Data Sources:
- Images: Download from [Physionet](https://physionet.org/content/mimic-cxr-jpg/2.0.0/).
- Annotations: Obtain annotations.json from  [R2Gen](https://github.com/cuhksz-nlp/R2Gen)

Directory Setup:
```
dataset/
â””â”€â”€ mimic_cxr/
    â”œâ”€â”€ images/                   # Place MIMIC-CXR image files here
    â””â”€â”€ annotations.json          # Chen et al. labels
```

**Note:** This dataset requires authorization.
   

### IU X-Ray Dataset:
Data Sources:
- Images & Annotations: Download PNG format images and annotations.json from R2Gen
Directory Setup:
```
dataset/
â””â”€â”€ iu_x-ray/
    â”œâ”€â”€ images/                   # Place IU X-Ray PNG images here
    â””â”€â”€ annotations.json          # Corresponding annotations
```

---

## ğŸ’¡ Execution Steps

### 1. Data Preprocessing  
#### **Annotation Processing**  
- **Input**: `annotation.json`  
- **Transformation**:  
  - Extract radiology reports.  
  - Parse disease-organ pairs using the format:  
    ```plaintext
    <disease> in <organ>
    ```  
  - Generate question-answer pairs by:  
    1. Randomly selecting questions from `tools/question/`.  
    2. Pairing with corresponding anatomical findings.  
- **Implementation**:  
  - See `tools/process` for detailed processing workflow.  

### 2. Model Training & Validation  
- Run the following command:  
  ```bash
  python main.py
  ```  
---

